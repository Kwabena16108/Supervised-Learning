{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c038d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import (train_test_split, cross_val_score,\n",
    "                                     cross_val_predict, GridSearchCV, RandomizedSearchCV)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import datetime as dt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62166123",
   "metadata": {},
   "source": [
    "# 1.0 Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83c42e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "import talib as ta\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d430e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download 30 years of daily data from Yahoo Finance\n",
    "\n",
    "tickers = ['SPY']\n",
    "df = yf.download(\" \".join(tickers), period='30y', interval='1d', group_by='tickers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87148928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77eb665d",
   "metadata": {},
   "source": [
    "# 1.1 Define predictor variables and a target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eb04a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0d8adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time features\n",
    "df['year'] = df.loc[:, 'Date'].dt.year\n",
    "df['month'] = df.loc[:, 'Date'].dt.month\n",
    "df['day_of_week'] = df.loc[:, 'Date'].dt.day_of_week\n",
    "df['week'] = df.loc[:, 'Date'].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb70cb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.copy()\n",
    "tmp.set_index(\"Date\", inplace=True)\n",
    "tmp = tmp.loc[:,'Adj Close'].rolling(7).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47d023e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "fig, axl = plt.subplots()\n",
    "fig.set_size_inches(10,7)\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "axl.plot(tmp.dropna().index, tmp.dropna(), label='Price', color='black')\n",
    "axl.vlines(dt.datetime(2003,1,30), ymin=0, ymax=400, color='blue')\n",
    "axl.vlines(dt.datetime(2009,1,30), ymin=0, ymax=400, color='blue')\n",
    "axl.vlines(dt.datetime(2020,2,29), ymin=0, ymax=400, color='blue')\n",
    "plt.ylabel('Price')\n",
    "plt.xlabel('Date')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76055eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2c886f",
   "metadata": {},
   "source": [
    "## 1.1.1 Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8eb48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# High - Low\n",
    "df['H-L'] = df.High - df.Low\n",
    "# Open - Close\n",
    "df['O-C'] = df.Open - df.Close\n",
    "# Correlation\n",
    "df['volume_by_adv20'] = df.Volume/df.Volume.rolling(20).mean()\n",
    "\n",
    "# Pass previous High, Low, Close for the alogoritm to have a sense of volatility in the past\n",
    "df['Prev_High'] = df['High'].shift(1)\n",
    "df['Prev_Low'] = df['Low'].shift(1)\n",
    "df['Prev_Close'] = df['Close'].shift(1)\n",
    "\n",
    "# Create columns 'OO' with the difference between the current minute's open and last day's open\n",
    "df['OO'] = df['Open']-df['Open'].shift(1)\n",
    "\n",
    "# Create columns 'OC' with the difference between the current minute's open and prevo\n",
    "df['OC'] = df['Open']-df['Prev_Close']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc90da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# TECHNICAL INDICATORS ######################\n",
    "def get_momentum(prices, window):\n",
    "    momentum = prices / prices.shift(window) - 1\n",
    "    return momentum\n",
    "\n",
    "def get_bb(prices, window):\n",
    "    rm = prices.rolling(window).mean()\n",
    "    rstd = prices.rolling(window).std()\n",
    "    bbp = (prices - rm) / 2 * rstd\n",
    "    return bbp \n",
    "\n",
    "def get_psma(prices, window):\n",
    "    rm = prices.rolling(window).mean()\n",
    "    psma = prices.divide(rm, axis=0) - 1\n",
    "    return psma \n",
    "\n",
    "def get_pema(prices, window):\n",
    "    ema = prices.ewm(window).mean()\n",
    "    pema = prices.divide(ema, axis=0) - 1\n",
    "    return pema\n",
    "\n",
    "\n",
    "# Create a lookback period(n) = 10-days\n",
    "n=10\n",
    "\n",
    "# 1. Relative Strength Index (RSI)\n",
    "df['RSI'] = ta.RSI(df['Adj Close'].shift(-1), timeperiod=n)\n",
    "\n",
    "# 2. SMA\n",
    "df['SMA'] = df['Adj Close'].shift(1).rolling(window=n).mean()\n",
    "\n",
    "# 3. Correlation between Adj Close and SMA\n",
    "df['Corr'] = df['Adj Close'].shift(1).rolling(window=n).corr(df.SMA.shift(1))\n",
    "\n",
    "# 4. Parabolic SAR (stop and reverse)\n",
    "df['SAR'] = ta.SAR(df.High.shift(1), df.Low.shift(1), 0.2, 0.2)\n",
    "\n",
    "# 5. ADX (Average directional movement index)\n",
    "df['ADX'] = ta.ADX(df.High.shift(1), df.Low.shift(1), df.Open, timeperiod=n)\n",
    "\n",
    "# 6. NATR (Normalized average true range)\n",
    "df['NATR'] = ta.NATR(df.Low,df.High,df.Close, timeperiod=n)\n",
    "\n",
    "# 7. Bollinger bands\n",
    "df['BB'] = get_bb(df['Adj Close'], window=n)\n",
    "\n",
    "# 8. Price / SMA\n",
    "df['PSMA'] = get_psma(df['Adj Close'], window=n)\n",
    "\n",
    "# 9. Price / EMA\n",
    "df['PEMA'] = get_pema(df['Adj Close'], window=n)\n",
    "\n",
    "# 10. Momentum\n",
    "df['MOM'] = get_momentum(df['Adj Close'], window=n)\n",
    "df['MOM10'] = get_momentum(df['Adj Close'], window=20)\n",
    "df['MOM30'] = get_momentum(df['Adj Close'], window=30)\n",
    "df['MOM40'] = get_momentum(df['Adj Close'], window=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6729a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns\n",
    "df['ret1'] = df['Adj Close'].pct_change()\n",
    "\n",
    "df['ret5'] = df['ret1'].rolling(5).sum()\n",
    "df['ret10'] = df['ret1'].rolling(10).sum()\n",
    "df['ret20'] = df['ret1'].rolling(20).sum()\n",
    "df['ret40'] = df['ret1'].rolling(40).sum()\n",
    "\n",
    "# One-day future returns\n",
    "df['retFut1'] = df.ret1.shift(-1)\n",
    "\n",
    "# calculate past returns to help algorithm understand the trends in the last n periods\n",
    "for i in range(1, n):\n",
    "    df['return%i' % i] = df.retFut1.shift(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebf844f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the value of 'Corr' to -1 if it is less than -1\n",
    "df.loc[df.Corr < -1, 'Corr'] = -1\n",
    "\n",
    "# Change the value of 'Corr' to 1 if it is greater than 1\n",
    "df.loc[df['Corr'] > 1, 'Corr'] = 1\n",
    "\n",
    "# Drop the NaN values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071ab427",
   "metadata": {},
   "source": [
    "# 1.1.2 Train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f41b0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = .8\n",
    "split = int(t*len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292ee14f",
   "metadata": {},
   "source": [
    "# 1.1.3 Create output signals\n",
    "\n",
    "1. Hightest returns' quantile is assigned Signal 1 (or Buy)\n",
    "2. Middle quantile is assigned Signal 0 (or do nothing)\n",
    "3. Lowest quantile is assigned Signal -1 (or Sell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d932fe8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Signal'] = 0\n",
    "df.loc[df.retFut1 > df.retFut1[:split].quantile(q=0.66), 'Signal'] = 1\n",
    "df.loc[df.retFut1 < df.retFut1[:split].quantile(q=0.34), 'Signal'] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04327dac",
   "metadata": {},
   "source": [
    "### Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521f2f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "data = df.drop(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume','retFut1',\n",
    "       'return1', 'return2', 'return3', 'return4', 'return5', 'return6',\n",
    "       'return7', 'return8', 'return9'], axis=1)\n",
    "\n",
    "ProfileReport(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b827066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724097b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Date','Open','Close','Adj Close','Signal', 'High','Low', 'Volume', 'retFut1'], axis=1)\n",
    "y = df['Signal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a9af77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiclass classification\n",
    "Counter(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5457f09",
   "metadata": {},
   "source": [
    "# 1. DECISION TREE CLASSIFIER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03475dd",
   "metadata": {},
   "source": [
    "## Cost complexity pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e00ec11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d75b2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train, y_test = X[:split], X[split:], y[:split], y[split:]\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58df4b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(ccp_alphas[:-1], impurities[:-1], marker='o', drawstyle='steps-post')\n",
    "ax.set_xlabel('effective alpha')\n",
    "ax.set_ylabel('total impurity of leaves')\n",
    "ax.set_title(\"Total Impuritiy vs. effective Alpha for training set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f3ae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the decision tree using the effective alphas\n",
    "clfs = []\n",
    "\n",
    "for aa in ccp_alphas:\n",
    "    clf = DecisionTreeClassifier(random_state=42, ccp_alpha=aa)\n",
    "    clf.fit(X_train, y_train)\n",
    "    clfs.append(clf)\n",
    "    \n",
    "print(\n",
    "    f\"Number of nodes in the last tree is: {clfs[-1].tree_.node_count} with ccp_alpha: {ccp_alphas[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9c3c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show how the number of tree depth and nodes decrease as alpha increases\n",
    "\n",
    "clfs = clfs[:-1]\n",
    "ccp_alphas = ccp_alphas[:-1]\n",
    "\n",
    "node_counts = [clf.tree_.node_count for clf in clfs]\n",
    "depth = [clf.tree_.max_depth for clf in clfs]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6), nrows=2, ncols=1)\n",
    "ax[0].plot(ccp_alphas, node_counts, marker='o', drawstyle='steps-post')\n",
    "ax[0].set_xlabel('alpha')\n",
    "ax[0].set_ylabel('number of nodes')\n",
    "ax[0].set_title('Number of nodes vs alpha')\n",
    "ax[1].plot(ccp_alphas, depth, marker=\"o\", drawstyle=\"steps-post\")\n",
    "ax[1].set_xlabel(\"alpha\")\n",
    "ax[1].set_ylabel(\"depth of tree\")\n",
    "ax[1].set_title(\"Depth vs alpha\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5213a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = [clf.score(X_train, y_train) for clf in clfs]\n",
    "test_scores = [clf.score(X_test, y_test) for clf in clfs]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.set_xlabel(\"alpha\")\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.set_title(\"Accuracy vs alpha for training and testing sets\")\n",
    "ax.plot(ccp_alphas, train_scores, marker=\"o\", label=\"train\", drawstyle=\"steps-post\")\n",
    "ax.plot(ccp_alphas, test_scores, marker=\"o\", label=\"test\", drawstyle=\"steps-post\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe88d2e5",
   "metadata": {},
   "source": [
    "# Baseline Decision Tree\n",
    "\n",
    "This DT is un-pruned. This will act as a baseline for more improved versions of the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022ae4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train, y_test = X[:split], X[split:], y[:split], y[split:]\n",
    "\n",
    "baseline_model = DecisionTreeClassifier(random_state=42)\n",
    "baseline_model.fit(X_train, y_train)\n",
    "y_pred = baseline_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2ea001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "640b6438",
   "metadata": {},
   "source": [
    "# Hyper parameter Tuning\n",
    "\n",
    "1.resample the training set to oversample minority class\n",
    "\n",
    "The key hyperparameters in a DTree are\n",
    "* max_leaf_node,\n",
    "* max_features,\n",
    "* max_depth,\n",
    "* min_samples_leaf,\n",
    "* class_weight,\n",
    "* and ccp_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22fbfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4b1d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features to consider at every split\n",
    "max_features = [round(i, 2) for i in np.linspace(start=0.3, stop=1.0, num=5)]\n",
    "\n",
    "# Max depth of the tree\n",
    "max_depth = [round(x, 2) for x in np.linspace(start=2, stop=20, num=5)]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [int(x) for x in np.linspace(start=50, stop=600, num=20)]\n",
    "\n",
    "# Maximum leaves at each node\n",
    "max_leaf_nodes = [int(x) for x in np.linspace(start=100, stop=1000, num=20)]\n",
    "\n",
    "# Cost complexity penalty (pruning)\n",
    "ccp_alpha = [round(x, 4) for x in np.linspace(start=0.001, stop=0.05, num=100)]\n",
    "\n",
    "param_grid = {'max_features': max_features,\n",
    "              'max_depth': max_depth,\n",
    "              'min_samples_leaf': min_samples_leaf,\n",
    "              'max_leaf_nodes': max_leaf_nodes,\n",
    "              'ccp_alpha': ccp_alpha\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babd9f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier()\n",
    "cv = TimeSeriesSplit(n_splits=5)\n",
    "dt_rcv = RandomizedSearchCV(estimator=dtree,\n",
    "                              param_distributions=param_grid,\n",
    "                              n_iter=50,\n",
    "                              random_state=42,\n",
    "                              cv=cv,\n",
    "                              n_jobs=8\n",
    "                              )\n",
    "\n",
    "# fit model\n",
    "dt_rcv.fit(X_train, y_train)\n",
    "# extract best params\n",
    "best_params = dt_rcv.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b74ad5",
   "metadata": {},
   "source": [
    "# Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0f0007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve, learning_curve\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5024ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "val_curve = ValidationCurve(DecisionTreeClassifier(),\n",
    "                            param_name='max_depth',\n",
    "                           param_range=max_depth,\n",
    "                           scoring='accuracy',\n",
    "                           n_jobs=-1,\n",
    "                            cv=TimeSeriesSplit(n_splits=5),\n",
    "                           ax=ax)\n",
    "\n",
    "val_curve.fit(X_train, y_train)\n",
    "val_curve.poof()\n",
    "sns.despine()\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee5332f",
   "metadata": {},
   "source": [
    "# Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd09c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_rcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b6cb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "(pd.Series(dt_rcv.best_estimator_.feature_importances_, \n",
    "           index=X.columns)\n",
    " .sort_values(ascending=False)\n",
    " .iloc[:5]\n",
    " .sort_values()\n",
    " .plot.barh(ax=ax, title='DT Feature Importance'))\n",
    "sns.despine()\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84370007",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "learn_curve = LearningCurve(dt_rcv.best_estimator_,\n",
    "                           train_sizes=np.arange(.1, 1.01, .1),\n",
    "                           scoring='accuracy',\n",
    "                           cv=TimeSeriesSplit(n_splits=5),\n",
    "                           ax=ax)\n",
    "\n",
    "learn_curve.fit(X_train, y_train)\n",
    "learn_curve.poof()\n",
    "sns.despine()\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eccf24",
   "metadata": {},
   "source": [
    "# Final model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d646924",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd2e99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=20.0,\n",
    "                              max_features=1.0,\n",
    "                              max_leaf_nodes=1000,\n",
    "                              min_samples_leaf=78,\n",
    "                              ccp_alpha=.0069)\n",
    "%time model.fit(X_train, y_train)\n",
    "%time y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62864616",
   "metadata": {},
   "source": [
    "# K-fold Cross Validation (Generalization Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba75a627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee18411",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score = cross_val_score(estimator=model,\n",
    "                          X=X_train,\n",
    "                          y=y_train,\n",
    "                          cv=TimeSeriesSplit(n_splits=10),\n",
    "                          n_jobs=-1,\n",
    "                          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f026d096",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538b1fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Accuracy: %.3f%% (%.3f%%)\" % (cv_score.mean()*100.0, cv_score.std()*100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151c5f44",
   "metadata": {},
   "source": [
    "# Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fcf40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f480c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=False)\n",
    "y_score = cross_val_predict(model, X=X, y=y, cv=kf.split(X),method='predict_proba')\n",
    "\n",
    "pred_scores = dict(y_true=y, y_score=y_score)\n",
    "\n",
    "# ROC AUC\n",
    "roc_auc_score(**pred_scores, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2345326",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132e87b9",
   "metadata": {},
   "source": [
    "# 2. DECISION TREE CLASSIFIER WITH adaBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d103494",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ac27f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442a0c40",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16ea3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search AdaBoost\n",
    "param_grid = {'n_estimators': [int(x)for x in np.linspace(1, 50, 10)]}\n",
    "\n",
    "ada = AdaBoostClassifier(\n",
    "                base_estimator = DecisionTreeClassifier(\n",
    "                            ccp_alpha=0.0069,\n",
    "                            max_depth=20,\n",
    "                            max_features=1.0,\n",
    "                            max_leaf_nodes=1000,\n",
    "                            min_samples_leaf=78),\n",
    "                n_estimators = 50,\n",
    "                random_state = 42\n",
    "            )\n",
    "cv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "ada_rcv = GridSearchCV(estimator=ada,\n",
    "                              param_grid=param_grid,\n",
    "                              cv=cv,\n",
    "                              n_jobs=8\n",
    "                              )\n",
    "\n",
    "# fit model\n",
    "ada_rcv.fit(X_train, y_train)\n",
    "# extract best params\n",
    "best_params = ada_rcv.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ee73e7",
   "metadata": {},
   "source": [
    "# Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e1c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start=1, stop=50, num=10)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "val_curve_2 = ValidationCurve(ada,\n",
    "                      param_name='n_estimators',\n",
    "                      param_range=n_estimators,\n",
    "                      cv=TimeSeriesSplit(n_splits=5),\n",
    "                      scoring='accuracy',\n",
    "                      n_jobs=-1,\n",
    "                      ax=ax)\n",
    "val_curve_2.fit(X_train, y_train)\n",
    "val_curve_2.poof()\n",
    "sns.despine()\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f280730b",
   "metadata": {},
   "source": [
    "# Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68239653",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "learn_curve = LearningCurve(ada,\n",
    "                           train_sizes=np.arange(.1, 1.01, .1),\n",
    "                           scoring='accuracy',\n",
    "                           cv=TimeSeriesSplit(n_splits=5),\n",
    "                           ax=ax)\n",
    "\n",
    "learn_curve.fit(X_train, y_train)\n",
    "learn_curve.poof()\n",
    "sns.despine()\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3258bf39",
   "metadata": {},
   "source": [
    "# Final model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caccdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the AdaBoost model\n",
    "ada_boost = AdaBoostClassifier(\n",
    "                base_estimator = DecisionTreeClassifier(\n",
    "                            ccp_alpha=0.0069,\n",
    "                            max_depth=20,\n",
    "                            max_features=1.0,\n",
    "                            max_leaf_nodes=1000,\n",
    "                            min_samples_leaf=78),\n",
    "                n_estimators = 6,\n",
    "                random_state = 42\n",
    "            )\n",
    "\n",
    "%time ada_boost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791cbd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time y_pred = ada_boost.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a40512",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  DTree tune model results\n",
    "                precision    recall  f1-score   support\n",
    "\n",
    "          -1       0.79      0.66      0.72       400\n",
    "           0       0.57      0.59      0.58       595\n",
    "           1       0.58      0.63      0.60       458\n",
    "\n",
    "    accuracy                           0.62      1453\n",
    "   macro avg       0.65      0.63      0.63      1453\n",
    "weighted avg       0.63      0.62      0.63      1453\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b6c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "(pd.Series(ada_boost.feature_importances_, \n",
    "           index=X.columns)\n",
    " .sort_values(ascending=False)\n",
    " .iloc[:10]\n",
    " .sort_values()\n",
    " .plot.barh(ax=ax, title='adaBOOST DT Feature Importance'))\n",
    "sns.despine()\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4415ccaa",
   "metadata": {},
   "source": [
    "# K-fold Cross Validation (Generalization Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4730cb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score = cross_val_score(estimator=ada_boost,\n",
    "                          X=X_train,\n",
    "                          y=y_train,\n",
    "                          cv=TimeSeriesSplit(n_splits=10),\n",
    "                          n_jobs=-1,\n",
    "                          verbose=1)\n",
    "\n",
    "print(cv_score)\n",
    "print('-'*20)\n",
    "\"Accuracy: %.3f%% (%.3f%%)\" % (cv_score.mean()*100.0, cv_score.std()*100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bea0af8",
   "metadata": {},
   "source": [
    "# Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f3694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=False)\n",
    "y_score = cross_val_predict(model, X=X, y=y, cv=kf.split(X),method='predict_proba')\n",
    "\n",
    "pred_scores = dict(y_true=y, y_score=y_score)\n",
    "\n",
    "# ROC AUC\n",
    "roc_auc_score(**pred_scores, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2398fe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb1b020",
   "metadata": {},
   "source": [
    "# 3. k-NN CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d895c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tslearn.neighbors import KNeighborsTimeSeriesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927764b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a0ac8e7",
   "metadata": {},
   "source": [
    "# Baseline Model - KNN with L1-Manhattan (not suitable for time series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fb43e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Models (exploration)\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "pipe = Pipeline([('scaler', StandardScaler()), \n",
    "                 ('knn', KNeighborsClassifier())])\n",
    "\n",
    "param_grid = {\n",
    "    'knn__metric': ['minkowski', 'euclidean','manhattan'],\n",
    "    'knn__n_neighbors': tuple(range(5, 101, 10)),\n",
    "    'knn__weights': ['uniform','distance'],\n",
    "    'knn__p': [1,2]\n",
    "}\n",
    "\n",
    "estimator_knn = GridSearchCV(estimator=pipe,\n",
    "                        param_grid=param_grid,\n",
    "                        cv=tscv,\n",
    "                        scoring='roc_auc',\n",
    "                        n_jobs=-1)\n",
    "\n",
    "%time estimator_knn.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483fb42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_knn.best_params_ # uses L1 (manhattan distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68be402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = estimator_knn.best_estimator_\n",
    "\n",
    "%time knn_model.fit(X_train, y_train)\n",
    "%time y_pred = knn_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f883cc",
   "metadata": {},
   "source": [
    "# k-NN DTW (suitable for time series classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c4c4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "pipe = Pipeline([('scaler', StandardScaler()), \n",
    "                 ('knn', KNeighborsTimeSeriesClassifier())])\n",
    "\n",
    "param_grid = {\n",
    "    'knn__metric': ['dtw', 'ctw','softdtw'],\n",
    "    'knn__n_neighbors': tuple(range(5, 101, 10)),\n",
    "    'knn__weights': ['uniform','distance']\n",
    "}\n",
    "\n",
    "estimator_knn = GridSearchCV(estimator=pipe,\n",
    "                        param_grid=param_grid,\n",
    "                        cv=tscv,\n",
    "                        scoring='roc_auc',\n",
    "                        n_jobs=-1)\n",
    "\n",
    "estimator_knn.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03a84cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_knn.best_params_ # uses dtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3c91b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_dtw = KNeighborsTimeSeriesClassifier(n_neighbors=5,\n",
    "                                     weights='uniform',\n",
    "                                    metric='dtw',\n",
    "                                    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a14d291",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ss = StandardScaler().fit(X_train)\n",
    "\n",
    "%time knn_dtw.fit(ss.fit_transform(X_train), y_train)\n",
    "\n",
    "%time y_pred=knn_dtw.predict(ss.fit_transform(X_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3cc101",
   "metadata": {},
   "source": [
    "# Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1d7ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.model_selection import ValidationCurve, LearningCurve\n",
    "from sklearn.model_selection import validation_curve, learning_curve\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa8126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_knn.best_params_ # use knn (not suitable for time series for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf57586",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = tuple(range(5, 101, 10))\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "val_curve = ValidationCurve(KNeighborsClassifier(metric='minkowski',\n",
    "                                                 p=1, weights='uniform'),\n",
    "                      param_name='n_neighbors',\n",
    "                      param_range=n_neighbors,\n",
    "                      cv=tscv,\n",
    "                      scoring='accuracy',\n",
    "                      n_jobs=-1,\n",
    "                      ax=ax)\n",
    "val_curve.fit(X_train, y_train)\n",
    "val_curve.poof()\n",
    "sns.despine()\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a47cdd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "beaf2ce8",
   "metadata": {},
   "source": [
    "# Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4a904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "learn_curve = LearningCurve(KNeighborsClassifier(),\n",
    "                           train_sizes=np.arange(.1, 1.01, .1),\n",
    "                           scoring='accuracy',\n",
    "                           cv=TimeSeriesSplit(n_splits=5),\n",
    "                           ax=ax)\n",
    "\n",
    "learn_curve.fit(X_train, y_train)\n",
    "learn_curve.poof()\n",
    "sns.despine()\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f699a9ae",
   "metadata": {},
   "source": [
    "# K-fold Cross Validation (Generalization Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f260eda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438e21b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score = cross_val_score(estimator=estimator_knn.best_estimator_,\n",
    "                          X=X_train,\n",
    "                          y=y_train,\n",
    "                          cv=TimeSeriesSplit(n_splits=10),\n",
    "                          n_jobs=-1,\n",
    "                          verbose=1)\n",
    "\n",
    "print(cv_score)\n",
    "print('-'*20)\n",
    "\"Accuracy: %.3f%% (%.3f%%)\" % (cv_score.mean()*100.0, cv_score.std()*100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19825f64",
   "metadata": {},
   "source": [
    "# Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd9efd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=False)\n",
    "y_score = cross_val_predict(estimator_knn.best_estimator_,\n",
    "                            X=X, y=y, cv=kf.split(X),method='predict_proba')\n",
    "\n",
    "pred_scores = dict(y_true=y, y_score=y_score)\n",
    "\n",
    "# ROC AUC\n",
    "roc_auc_score(**pred_scores, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d45c8e",
   "metadata": {},
   "source": [
    "# 4. SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6f4c04",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20d8ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c61b037",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('scaler', StandardScaler()), ('svc', SVC())]\n",
    "pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c309f94",
   "metadata": {},
   "source": [
    "### Gaussian Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d5bb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the different input for C and gamma\n",
    "# C <-- the regularization parameter (trade-off between error and decision boundary)\n",
    "# gamma <-- determines how far the influence of a single training example reaches \n",
    "C = [1e1, 1e2, 1e3, 1e4, 1e5]\n",
    "gamma = [1e-3, 1e-2, 1e-1, 1e0]\n",
    "\n",
    "# Initialize parameters\n",
    "parameters = {'svc__C': C,\n",
    "             'svc__gamma': gamma,\n",
    "             'svc__kernel': ['rbf']\n",
    "             }\n",
    "\n",
    "rbf_rcv = RandomizedSearchCV(estimator=pipeline,\n",
    "                        param_distributions=parameters,\n",
    "                        cv=tscv,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "# Training on and fetching the best parameters\n",
    "rbf_rcv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf48d224",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_rcv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7753c0ba",
   "metadata": {},
   "source": [
    "### Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67b690d",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [1e2, 1e3, 1e4, 1e5,1e6]\n",
    "gamma = [1e-3, 1e-2, 1e-1, 1e0, 0.0]\n",
    "\n",
    "# Initialize parameters\n",
    "parameters = {'svc__C': C,\n",
    "             'svc__gamma': gamma,\n",
    "             'svc__kernel': ['poly']\n",
    "             }\n",
    "\n",
    "poly_rcv = RandomizedSearchCV(estimator=pipeline,\n",
    "                        param_distributions=parameters,\n",
    "                        cv=tscv,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "# Training on and fetching the best parameters\n",
    "poly_rcv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47fc824",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_rcv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c868ec0",
   "metadata": {},
   "source": [
    "### Sigmoid kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b03a202",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [1e2, 1e3, 1e4, 1e5,1e6]\n",
    "gamma = [1e-3, 1e-2, 1e-1, 1e0, 0.0]\n",
    "\n",
    "# Initialize parameters\n",
    "parameters = {'svc__C': C,\n",
    "             'svc__gamma': gamma,\n",
    "             'svc__kernel': ['sigmoid']\n",
    "             }\n",
    "\n",
    "sig_rcv = RandomizedSearchCV(estimator=pipeline,\n",
    "                        param_distributions=parameters,\n",
    "                        cv=tscv,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "# Training on and fetching the best parameters\n",
    "sig_rcv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8b6e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_rcv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cf872c",
   "metadata": {},
   "source": [
    "# Final model prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d217e59",
   "metadata": {},
   "source": [
    "### Gaussian kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7828d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SVC with the optimized hyperparameters from gridsearch\n",
    "svc_rbf = rbf_rcv.best_estimator_\n",
    "\n",
    "# Pass the scaled train data to the SVC classifier\n",
    "%time svc_rbf.fit((X_train), y_train)\n",
    "\n",
    "# Pass the test data to the predict function \n",
    "%time y_pred = svc_rbf.predict((X_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f946262",
   "metadata": {},
   "source": [
    "### Polynomial kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1221cf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SVC with the optimized hyperparameters from gridsearch\n",
    "svc_poly = poly_rcv.best_estimator_\n",
    "\n",
    "# Pass the scaled train data to the SVC classifier\n",
    "%time svc_poly.fit((X_train), y_train)\n",
    "\n",
    "# Pass the test data to the predict function \n",
    "%time y_pred = svc_poly.predict((X_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecebdc44",
   "metadata": {},
   "source": [
    "### Sigmoid kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188e35e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SVC with the optimized hyperparameters from gridsearch\n",
    "svc_sig = sig_rcv.best_estimator_\n",
    "\n",
    "# Pass the scaled train data to the SVC classifier\n",
    "%time svc_sig.fit((X_train), y_train)\n",
    "\n",
    "# Pass the test data to the predict function \n",
    "%time y_pred = svc_sig.predict((X_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b767ec5",
   "metadata": {},
   "source": [
    "# Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0d3dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea5fb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varying gamma\n",
    "gamma = [i for i in np.linspace(0.0001, 0.001, 10)]\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "val_curve_1 = ValidationCurve(SVC(C=100, kernel='rbf', probability=True),\n",
    "                      param_name='gamma',\n",
    "                      param_range=gamma,\n",
    "                      cv=TimeSeriesSplit(n_splits=5),\n",
    "                      scoring='accuracy',\n",
    "                      n_jobs=-1,\n",
    "                      ax=ax)\n",
    "val_curve_1.fit(X_train, y_train)\n",
    "val_curve_1.poof()\n",
    "sns.despine()\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c7d468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varying C\n",
    "C = [1e2, 1e3, 1e4, 1e5,1e6]\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "val_curve_2 = ValidationCurve(SVC(kernel='rbf', gamma=0.001, probability=True),\n",
    "                      param_name='C',\n",
    "                      param_range=C,\n",
    "                      cv=TimeSeriesSplit(n_splits=5),\n",
    "                      scoring='accuracy',\n",
    "                      n_jobs=2,\n",
    "                      ax=ax)\n",
    "val_curve_2.fit(X_train, y_train)\n",
    "val_curve_2.poof()\n",
    "sns.despine()\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab70b35f",
   "metadata": {},
   "source": [
    "# Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b2d5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "l_curve = LearningCurve(SVC(C=100, kernel='rbf', gamma=0.001, probability=True), \n",
    "                        train_sizes=np.arange(.1, 1.01, .1),\n",
    "                        scoring='accuracy', \n",
    "                        cv=TimeSeriesSplit(n_splits=5), \n",
    "                        n_jobs=8,\n",
    "                        ax=ax)\n",
    "l_curve.fit(X_train, y_train)\n",
    "l_curve.poof()\n",
    "sns.despine()\n",
    "fig.tight_layout();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a344a987",
   "metadata": {},
   "source": [
    "## k-Fold cross validation (generalization error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76434457",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_score = cross_val_score(estimator=rbf_rcv.best_estimator_,\n",
    "                          X=ss.fit_transform(X_train),\n",
    "                          y=y_train,\n",
    "                          cv=TimeSeriesSplit(n_splits=10),\n",
    "                          n_jobs=-1,\n",
    "                          verbose=1)\n",
    "\n",
    "print(cv_score)\n",
    "print('-'*20)\n",
    "\"Accuracy: %.3f%% (%.3f%%)\" % (cv_score.mean()*100.0, cv_score.std()*100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb2d86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score = cross_val_score(estimator=poly_rcv.best_estimator_,\n",
    "                          X=ss.fit_transform(X_train),\n",
    "                          y=y_train,\n",
    "                          cv=TimeSeriesSplit(n_splits=10),\n",
    "                          n_jobs=-1,\n",
    "                          verbose=1)\n",
    "\n",
    "print(cv_score)\n",
    "print('-'*20)\n",
    "\"Accuracy: %.3f%% (%.3f%%)\" % (cv_score.mean()*100.0, cv_score.std()*100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8025655b",
   "metadata": {},
   "source": [
    "## Performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a702f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_rcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4e0c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=False)\n",
    "y_score = cross_val_predict(SVC(C=100.0, gamma=0.001, probability=True),\n",
    "                            X=ss.transform(X), y=y,\n",
    "                           cv=kf.split(ss.transform(X)),\n",
    "                            method='predict_proba')\n",
    "\n",
    "pred_scores = dict(y_true=y, y_score=y_score)\n",
    "\n",
    "# ROC AUC\n",
    "roc_auc_score(**pred_scores, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e349087",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_rcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0894bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=False)\n",
    "y_score = cross_val_predict(SVC(C=1000.0, gamma=0.01, kernel='poly', probability=True),\n",
    "                            X=ss.transform(X), y=y,\n",
    "                           cv=kf.split(ss.transform(X)),\n",
    "                            method='predict_proba')\n",
    "\n",
    "pred_scores = dict(y_true=y, y_score=y_score)\n",
    "\n",
    "# ROC AUC\n",
    "roc_auc_score(**pred_scores, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afdeb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb24b7c1",
   "metadata": {},
   "source": [
    "# 5. Neutral Networks (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52664690",
   "metadata": {},
   "source": [
    "## Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cde1b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618e5102",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('scaler', StandardScaler()), ('mlp', MLPClassifier(random_state=42))]\n",
    "pipeline = Pipeline(steps)\n",
    "ss = StandardScaler().fit(X_train)\n",
    "\n",
    "# Initialize parameters\n",
    "\n",
    "parameters = {\n",
    "    'mlp__hidden_layer_sizes': [(40, 30, 100), (40, 30, 40),\n",
    "                                (30, 20, 30), (20, 20, 20, 10)],\n",
    "    'mlp__activation': ['tanh', 'relu', 'logistic'],\n",
    "    'mlp__solver': ['sgd', 'adam', 'lbfgs'],\n",
    "    'mlp__alpha': [0.0001,0.001,0.01, 0.05],\n",
    "    'mlp__learning_rate': ['constant','adaptive'],\n",
    "    'mlp__early_stopping':[True, False] }\n",
    "\n",
    "mlp_gcv = GridSearchCV(estimator=pipeline,\n",
    "                        param_grid=parameters,\n",
    "                        cv=TimeSeriesSplit(n_splits=5),\n",
    "                        scoring='roc_auc',\n",
    "                        n_jobs=8)\n",
    "\n",
    "# Training on and fetching the best parameters\n",
    "mlp_gcv.fit(ss.transform(X_train), y_train)\n",
    "\n",
    "# Obtain the best parameters\n",
    "best_hidden_layer_sizes = mlp_gcv.best_params_['mlp__hidden_layer_sizes']\n",
    "best_activation = mlp_gcv.best_params_['mlp__activation']\n",
    "best_solver = mlp_gcv.best_params_['mlp__solver']\n",
    "best_alpha = mlp_gcv.best_params_['mlp__alpha']\n",
    "best_learning_rate = mlp_gcv.best_params_['mlp__learning_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd714a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_gcv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5611c0eb",
   "metadata": {},
   "source": [
    "## Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b82b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(40, 30, 100),activation='tanh',random_state=42,\n",
    "                       solver='sgd',learning_rate='constant',alpha= 0.0001, early_stopping=False, max_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9651ab8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "val_curve_2 = ValidationCurve(mlp,\n",
    "                      param_name='max_iter',\n",
    "                      param_range=np.arange(1,25),\n",
    "                      cv=TimeSeriesSplit(n_splits=5),\n",
    "                      scoring='accuracy',\n",
    "                      n_jobs=-1,\n",
    "                      ax=ax)\n",
    "val_curve_2.fit(X_train, y_train)\n",
    "val_curve_2.poof()\n",
    "sns.despine()\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b8fb1e",
   "metadata": {},
   "source": [
    "# Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6075a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "l_curve = LearningCurve(MLPClassifier(hidden_layer_sizes=(40, 30, 100),\n",
    "                        activation='tanh',random_state=42,\n",
    "                        solver='sgd',learning_rate='constant',\n",
    "                        alpha= 0.0001, early_stopping=False, \n",
    "                        max_iter=200), \n",
    "                        train_sizes=np.arange(.1, 1.01, .1),\n",
    "                        scoring='accuracy', \n",
    "                        cv=TimeSeriesSplit(n_splits=5), \n",
    "                        n_jobs=8,\n",
    "                        ax=ax)\n",
    "l_curve.fit(X_train, y_train)\n",
    "l_curve.poof()\n",
    "sns.despine()\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4805810f",
   "metadata": {},
   "source": [
    "# Training (loss) curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6702e7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(40, 30, 100),activation='tanh',random_state=42,\n",
    "                       solver='sgd',learning_rate='constant',alpha= 0.0001, early_stopping=False, max_iter=200)\n",
    "\n",
    "# re-split training data into traing and validation set\n",
    "t = .8\n",
    "split = int(t*len(X_train))\n",
    "X_tr,X_val,y_tr,y_val=X_train[:split], X_train[split:], y_train[:split], y_train[split:]\n",
    "\n",
    "\n",
    "mlp.fit(X_tr, y_tr)\n",
    "print(mlp.score(X_tr, y_tr))\n",
    "plt.plot(mlp.loss_curve_, label='Training loss')\n",
    "mlp.fit(X_val, y_val)\n",
    "plt.plot(mlp.loss_curve_,label='Validation loss')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e93a4c8",
   "metadata": {},
   "source": [
    "# Final model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdc2a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create MLP with the optimized hyperparameters from gridsearch\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(40, 30, 100),\n",
    "                        activation='tanh',random_state=42,\n",
    "                        solver='sgd',learning_rate='constant',\n",
    "                        alpha= 0.0001, early_stopping=False, \n",
    "                        max_iter=200)\n",
    "\n",
    "ss = StandardScaler().fit(X_train)\n",
    "\n",
    "# Pass the scaled train data to the MLP classifier\n",
    "%time mlp_model.fit(ss.fit_transform(X_train), y_train)\n",
    "\n",
    "# Pass the test data to the predict function \n",
    "%time y_pred = mlp_model.predict(ss.transform(X_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6882bd8",
   "metadata": {},
   "source": [
    "## k-Fold Cross Validation (Generalization error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fde138e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_score = cross_val_score(estimator=mlp_model,\n",
    "                          X=ss.fit_transform(X_train),\n",
    "                          y=y_train,\n",
    "                          cv=TimeSeriesSplit(n_splits=10),\n",
    "                          n_jobs=-1,\n",
    "                          verbose=1)\n",
    "\n",
    "print(cv_score)\n",
    "print('-'*20)\n",
    "\"Accuracy: %.3f%% (%.3f%%)\" % (cv_score.mean()*100.0, cv_score.std()*100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf70a14",
   "metadata": {},
   "source": [
    "## Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3637cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=False)\n",
    "y_score = cross_val_predict(mlp_model, X=ss.transform(X), y=y,\n",
    "                           cv=kf.split(ss.transform(X)),\n",
    "                            method='predict_proba')\n",
    "\n",
    "pred_scores = dict(y_true=y, y_score=y_score)\n",
    "\n",
    "# ROC AUC\n",
    "roc_auc_score(**pred_scores, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7994895",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SP500 cumulative return\n",
    "df['sp500_cum_ret']=df.ret1.cumsum()\n",
    "\n",
    "# NN performance\n",
    "df['predicted_signal_nn'] = mlp_model.predict(ss.fit_transform(X))\n",
    "df['strategy_returns_nn']=df.retFut1 * df.predicted_signal_nn\n",
    "\n",
    "# SVC performance\n",
    "df['predicted_signal_svc_rbf'] = svc_rbf.predict(ss.fit_transform(X))\n",
    "df['strategy_returns_svc_rbf']=df.retFut1 * df.predicted_signal_svc_rbf\n",
    "\n",
    "df['predicted_signal_svc_poly'] = svc_poly.predict(ss.fit_transform(X))\n",
    "df['strategy_returns_svc_poly']=df.retFut1 * df.predicted_signal_svc_poly\n",
    "\n",
    "# k-NN performance (k=5)\n",
    "df['predicted_signal_knn_manh'] = knn_model.predict(ss.fit_transform(X))\n",
    "df['strategy_returns_knn_manh']=df.retFut1 * df.predicted_signal_knn_manh\n",
    "\n",
    "# DTree\n",
    "df['predicted_signal_dt'] = model.predict(X)\n",
    "df['strategy_returns_dt']=df.retFut1 * df.predicted_signal_dt\n",
    "\n",
    "# adaBoost DTree\n",
    "df['predicted_signal_ada'] = ada_boost.predict(X)\n",
    "df['strategy_returns_ada']=df.retFut1 * df.predicted_signal_ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ad6af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "insample_period = df[:split]\n",
    "outsample_period = df[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0da6559",
   "metadata": {},
   "outputs": [],
   "source": [
    "insample_period['sp500_cum_ret']=insample_period.ret1.cumsum()\n",
    "insample_period['nn_cum_ret']=insample_period.strategy_returns_nn.cumsum()\n",
    "insample_period['svc_rbf_cum_ret'] = insample_period.strategy_returns_svc_rbf.cumsum()\n",
    "insample_period['svc_poly_cum_ret'] = insample_period.strategy_returns_svc_poly.cumsum()\n",
    "insample_period['knn_cum_ret'] = insample_period.strategy_returns_knn_manh.cumsum()\n",
    "insample_period['dt_cum_ret'] = insample_period.strategy_returns_dt.cumsum()\n",
    "insample_period['ada_cum_ret'] = insample_period.strategy_returns_ada.cumsum()\n",
    "\n",
    "outsample_period['sp500_cum_ret']=outsample_period.ret1.cumsum()\n",
    "outsample_period['nn_cum_ret']=outsample_period.strategy_returns_nn.cumsum()\n",
    "outsample_period['svc_rbf_cum_ret'] = outsample_period.strategy_returns_svc_rbf.cumsum()\n",
    "outsample_period['svc_poly_cum_ret'] = outsample_period.strategy_returns_svc_poly.cumsum()\n",
    "outsample_period['knn_cum_ret'] = outsample_period.strategy_returns_knn_manh.cumsum()\n",
    "outsample_period['dt_cum_ret'] = outsample_period.strategy_returns_dt.cumsum()\n",
    "outsample_period['ada_cum_ret'] = outsample_period.strategy_returns_ada.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1050a729",
   "metadata": {},
   "outputs": [],
   "source": [
    "insample_returns = insample_period.loc[:, ['Date','sp500_cum_ret','nn_cum_ret','svc_rbf_cum_ret',\n",
    "                       'svc_poly_cum_ret','knn_cum_ret',\n",
    "                      'dt_cum_ret','ada_cum_ret']]\n",
    "\n",
    "insample_returns.set_index('Date', inplace=True)\n",
    "insample_returns.columns =['SPY_ETF','NN','SVC_rbf','SVC_poly','KNN','DTree','DTree_adaboost']\n",
    "\n",
    "# one plug correction for normalisation (to be used for comaprison of returns)\n",
    "insample_returns.iloc[0, :] = insample_returns.iloc[0, :]+0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd495e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axl = plt.subplots()\n",
    "fig.set_size_inches(9,6)    \n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "axl.plot(insample_returns.index, insample_returns.SPY_ETF,'-', color='black', label='Benchmark (SP500)')\n",
    "axl.plot(insample_returns.index, insample_returns.NN,'-', color='red', label='Neural Networks (MLP)')\n",
    "axl.plot(insample_returns.index, insample_returns.SVC_rbf,'-', color='green', label='SVC(Gaussian kernel)')\n",
    "axl.plot(insample_returns.index, insample_returns.SVC_poly,'-', color='blue', label='SVC(Polynomial kernel)')\n",
    "axl.plot(insample_returns.index, insample_returns.KNN,'-', color='magenta', label='KNN(Manhattan distance)')\n",
    "axl.plot(insample_returns.index, insample_returns.DTree,'-', color='cyan', label='Decision Tree')\n",
    "axl.plot(insample_returns.index, insample_returns.DTree_adaboost,'-', color='yellow', label='Decision Tree (boosted)')\n",
    "axl.legend(frameon=True)\n",
    "axl.legend(loc='upper left')\n",
    "axl.set_xlabel('Date')\n",
    "axl.set_ylabel('Cumulative Returns(%)')\n",
    "axl.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9a4df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "outsample_returns = outsample_period.loc[:, ['Date','sp500_cum_ret','nn_cum_ret','svc_rbf_cum_ret',\n",
    "                       'svc_poly_cum_ret','knn_cum_ret',\n",
    "                      'dt_cum_ret','ada_cum_ret']]\n",
    "\n",
    "outsample_returns.set_index('Date', inplace=True)\n",
    "outsample_returns.columns =['SPY_ETF','NN','SVC_rbf','SVC_poly','KNN','DTree','DTree_adaboost']\n",
    "\n",
    "# one plug correction for normalisation (to be used for comaprison of returns)\n",
    "outsample_returns.iloc[0, :] = outsample_returns.iloc[0, :]+0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79532156",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axl = plt.subplots()\n",
    "fig.set_size_inches(10,6)    \n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "axl.plot(outsample_returns.index, outsample_returns.SPY_ETF,'-', color='black', label='Benchmark (SP500)')\n",
    "axl.plot(outsample_returns.index, outsample_returns.NN,'-', color='red', label='Neural Networks (MLP)')\n",
    "axl.plot(outsample_returns.index, outsample_returns.SVC_rbf,'-', color='green', label='SVC(Gaussian kernel)')\n",
    "axl.plot(outsample_returns.index, outsample_returns.SVC_poly,'-', color='blue', label='SVC(Polynomial kernel)')\n",
    "axl.plot(outsample_returns.index, outsample_returns.KNN,'-', color='magenta', label='KNN(Manhattan distance)')\n",
    "axl.plot(outsample_returns.index, outsample_returns.DTree,'-', color='cyan', label='Decision Tree')\n",
    "axl.plot(outsample_returns.index, outsample_returns.DTree_adaboost,'-', color='yellow', label='Decision Tree (boosted)')\n",
    "axl.legend(frameon=True)\n",
    "axl.legend(loc='best')\n",
    "axl.set_xlabel('Date')\n",
    "axl.set_ylabel('Cumulative Returns(%)')\n",
    "axl.vlines(x=outsample_returns.index=)\n",
    "axl.grid(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
